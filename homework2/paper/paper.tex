\documentclass[runningheads]{paper}

\usepackage{hyperref}   % hyperlinks
\usepackage{graphicx}
\usepackage{algorithm}
\usepackage[noend]{algpseudocode}
\usepackage{multirow}
\usepackage{longtable}
\usepackage{float}
\usepackage{array}

% Used for displaying a sample figure. If possible, figure files should
% be included in EPS format.
%
% If you use the hyperref package, please uncomment the following line
% to display URLs in blue roman font according to Springer's eBook style:
% \renewcommand\UrlFont{\color{blue}\rmfamily}

% ------------------------------------------------------------------------------

\begin{document}
%
\title{Exploring the Utility of Machine Learning Across Varied Data Formats}
%
\author{Cărămidă Iustina-Andreea - 332CA}
%
\institute{Faculty of Automatic Control and Computer Science \\
University Politehnica of Bucharest \\
\email{iustina.caramida@stud.acs.upb.ro}
}
%
\maketitle              % typeset the header of the contribution
%
\begin{abstract}
    This study investigates the applicability of machine learning techniques on 
    diverse datasets. We explore the effectiveness of two algorithms, Linear 
    Regression and Multi-Layered Perceptron (MLP), on predicting both health 
    outcomes and financial well-being. Specifically, we utilize a stroke 
    prediction dataset to assess the model\'s ability to identify individuals at 
    risk of stroke. Additionally, we employ a salary prediction dataset to 
    evaluate the model\'s capacity to classify individuals earning above a 
    specific income threshold (e.g., \$50,000 per year). Through comparative 
    analysis, this research aims to elucidate the strengths and limitations of 
    each algorithm when applied to these contrasting data types, offering 
    insights into their suitability for various prediction tasks. Furthermore, 
    we present a framework for data analysis, outlining essential steps for data
    cleaning, exploration, and preparation, which can be applied to enhance the 
    effectiveness of machine learning models across diverse datasets.

\keywords{\textit{Machine Learning \and Heterogeneous Data \and Comparative Analysis \and
Prediction Modeling \and Data Analysis Techniques \and Stroke Prediction \and
Salary Prediction \and Linear Regression \and Multi-Layered Perceptron \and 
DataPreprocessing} }

\end{abstract}
% ------------------------------------------------------------------------------
\section{Introduction}

\subsection{Motivation: The Power and Nuance of Machine Learning Data}
Machine learning (ML) has become a cornerstone of progress in numerous 
disciplines. Its ability to extract valuable insights from vast and complex 
datasets has fueled breakthroughs in healthcare, finance, and social sciences. 
However, the effectiveness of ML models is not a one-size-fits-all proposition. 
Different data types possess unique characteristics, and understanding these 
nuances is essential for selecting the most appropriate ML algorithms. Data can 
be structured (organized in tables) or unstructured (text, images), numerical 
or categorical, and may exhibit linear or non-linear relationships between 
features.  Choosing the right algorithm depends heavily on these factors. This 
research delves into this crucial aspect of ML application by exploring the 
performance of two distinct algorithms on contrasting datasets.

\subsection{Research Focus: Delving into Stroke Prediction and Salary Prediction}
This study focuses on the application of ML techniques to two contrasting 
datasets: stroke prediction and salary prediction. Stroke, a leading cause of 
disability and death globally, poses a significant public health burden. Stroke 
prediction models aim to identify individuals at high risk of experiencing a 
stroke, allowing for preventive measures and early intervention. These models 
typically analyze factors such as age, blood pressure, cholesterol levels, and 
smoking history.

Conversely, salary prediction models attempt to classify individuals based on 
income thresholds. This information can offer valuable insights into economic 
trends, such as income inequality, and inform policy decisions. Salary 
prediction models might analyze factors like education level, work experience, 
and industry sector. By investigating these two distinct datasets, this research 
aims to gain a broader understanding of how ML algorithms perform on different 
data types with varying underlying structures and complexities.

\subsection{Methodology: Unveiling the Algorithms - Linear Regression and Multi-Layered Perceptron}
To investigate the performance on these contrasting datasets, this study employs 
two prominent ML algorithms: Linear Regression and Multi-Layered Perceptron (MLP). 

Linear Regression is a well\-established technique known for its interpretability
and efficiency in uncovering linear relationships between features (data points) 
and target variables (what we want to predict). This makes it a valuable tool 
for understanding the underlying factors influencing a particular outcome, such 
as the relationship between blood pressure and stroke risk. However, its strength 
lies in capturing linear relationships. If the underlying relationships in the 
data are more complex and non-linear, then Linear Regression might not be as 
effective.

On the other hand, Multi-Layered Perceptrons (MLPs) are a type of artificial 
neural network capable of learning complex, non-linear patterns within data. 
Unlike Linear Regression, MLPs are not limited by linearity and can potentially 
capture more intricate relationships between features and target variables. This 
capability makes them particularly suitable for datasets with complex underlying 
structures, such as the factors influencing an individual's salary, which might 
involve a combination of education, experience, industry, and other factors 
interacting in non-linear ways.

\subsection{Research Objectives: Evaluating Algorithms, Unveiling Strengths and Weaknesses}
By comparatively analyzing the performance of Linear Regression and MLP on 
stroke and salary prediction tasks, this research seeks to achieve several key 
objectives:

\subsubsection{Evaluate the Suitability of Algorithms for Diverse Data Types:}
This involves assessing the effectiveness of each algorithm in capturing the 
underlying relationships within the stroke prediction and salary prediction 
datasets. We will determine which algorithm performs better on each dataset, 
offering insights into their suitability for different data types, such as 
linear datasets (blood pressure and stroke risk) versus potentially non-linear 
datasets (factors influencing salary).

\subsubsection{Gain Insights into Algorithmic Strengths and Weaknesses:}
By analyzing the comparative performance, we aim to highlight the scenarios where
each algorithm excels and identify areas where one might outperform the other. 
This will provide valuable guidance for researchers and practitioners in 
selecting the most appropriate algorithm for their specific prediction tasks. 
For instance, if interpretability is crucial (e.g., understanding the factors 
influencing stroke risk), Linear Regression might be preferred. If the data is 
likely to have complex, non-linear relationships, then an MLP might be a better 
choice.

\subsubsection{Demonstrate Best Practices for Data Analysis in ML Applications:}
Effective data analysis is crucial for building robust ML models. This research 
will showcase essential steps for data cleaning, exploration, and preparation, 
emphasizing their importance in enhancing model performance across diverse 
datasets. These steps may include handling missing values, identifying outliers, 
and feature engineering (creating new features from existing data) to improve 
the model's ability to learn from the data.

\subsection{Expected Contribution: Advancing the Application of ML on Heterogeneous Data}
Through this exploration, the research aims to contribute valuable knowledge to 
the field of machine learning, particularly the application of ML on 
heterogeneous datasets.  The findings can guide researchers and practitioners 
in selecting appropriate algorithms for their specific prediction tasks and 
data types.  Furthermore, by demonstrating best practices for data analysis, 
this research can contribute to the development of more robust and reliable ML 
models across diverse application domains. This can lead to advancements in 
areas like healthcare (improved stroke prediction for preventive measures) and 
economics (better understanding of factors influencing income inequality).  
Ultimately, the research aims to contribute to the responsible and effective use 
of ML for tackling complex problems across various fields.
% ------------------------------------------------------------------------------
\section{Exploratory Data Analysis}

\subsection{Datasets attributes description}
The initial and crucial step in developing any machine learning algorithm 
involves a thorough understanding of the data it will be trained on. This 
understanding is achieved through a comprehensive analysis of the datasets' 
characteristics. In this vein, the following sub sections will delve into the 
specific attributes of the two datasets employed in this study: stroke 
prediction and salary prediction.

A detailed description of each salary prediction attribute is provided in Table
\ref{tab:salary_attributes_description} and of each stroke  prediction attribute
in Table \ref{tab:stroke_attributes_description}.

\begin{center}
    \begin{longtable}{ |>{\centering\arraybackslash}p{3cm}||>{\centering\arraybackslash}p{2cm}|>{\centering\arraybackslash}p{6cm}| }
        \hline
        \multicolumn{3}{|c|}{List of all attributes in the Salary Prediction dataset} \\
        \hline
        Attribute name & Type & Details \\
        \hline
        fnl & numeric & Socio-economic characteristic of the population from which the individual comes \\
        \hline
        hpw & numeric & Number of work hours per week \\
        \hline
        relation & categorical & The type of relationship in which the individual is involved \\
        \hline
        gain & numeric & Capital gain \\
        \hline
        country & categorical & Country of origin \\
        \hline
        job & categorical & The individual's job \\
        \hline
        edu\_int & numeric & Number of years of study \\
        \hline
        years & numeric & Age of the individual \\
        \hline
        loss & numeric & Loss of capital \\
        \hline
        work\_type & categorical & The job's type \\
        \hline
        partner & categorical & The type of partner the individual has \\
        \hline
        edu & categorical & The individual's type of education \\
        \hline
        gender & categorical & Individual's gender \\
        \hline
        race & categorical & Individual's race \\
        \hline
        prod & numeric & Capital production \\
        \hline
        gtype & categorical & Type of employment contract \\
        \hline
        \caption{Salary Prediction Attributes}
        \label{tab:salary_attributes_description}
   \end{longtable}
\end{center}

\begin{center}
    \begin{longtable}{ |>{\centering\arraybackslash}m{3.5cm}||>{\centering\arraybackslash}m{2cm}|>{\centering\arraybackslash}m{3.5cm}||>{\centering\arraybackslash}m{2.5cm}| }
        \hline
        \multicolumn{4}{|c|}{List of all attributes in the Stroke Prediction dataset} \\
        \hline
        Attribute name & Type & Details & Possible values \\
        \hline
        mean\_blood\_sugar\_ level & numeric & The average value of blood glucose throughout the duration observation of the subject & \\
        \hline
        cardiovascular\_issues & categorical & Whether or not the subject has a medical history cardiovascular & 0, 1 \\
        \hline
        job\_category & categorical & The field in which the person works & child, entrepreneurial, N\_work\_history, private\_sector, public\_sector \\
        \hline
        body\_mass\_indicator & numeric & Body mass index, which indicates if the person is underweight, within limits normal, overweight or obese & \\
        \hline
        sex & categorical & The gender of the person & F, M\\
        \hline
        tobacco\_usage & categorical & Current or past smoker indicator &  ex-smoker, smoker, non-smoker\\
        \hline
        high\_blood\_pressure & categorical & Binary attribute indicating whether a person suffer from high blood pressure or not & 0, 1 \\
        \hline
        married & categorical & Binary attribute indicating whether the person a ever been married & Y, N \\
        \hline
        living\_area & categorical & The type of area where he lived most of his life & City, Countryside \\
        \hline
        years\_old & numeric & The person's age in years & \\
        \hline
        chaotic\_sleep & categorical & Binary attribute for a sleep program irregular & 0, 1 \\
        \hline
        analysis\_results & numeric & The results of medical analyzes of the person, which may include various measurements and indicators relevant to her health & \\
        \hline
        biological\_age\_index & numeric & An index that estimates the biological age of a person based on different factors such as lifestyle, health status, measured in an unknown unit & \\
        \hline
        cerebrovascular\_ accident & categorical & Binary indicator indicating whether the person a had a stroke or not & 0, 1 \\
        \hline
        \caption{Stroke Prediction Attributes}
        \label{tab:stroke_attributes_description}
   \end{longtable}
\end{center}

\subsection{Exploration of Attribute Types and Value Ranges}
Prior to applyinga machine learning model to a dataset, a crucial step involves
in identifying the types of attributes (features) present and their corresponding
values ranges. This anaysis is essential for selecting appropriate algorithms 
and ensuring optimalmodel performance. In the following pharagraphs we will
describe three primary attribute types.
\begin{itemize}
    \item \textit{Continuous Numeric Attributes:}
    These attributes possess numerical values that can theoretically take on any 
    value within a specific range. Examples might include: age, weight, temperature etc.
    \item \textit{Discrete Nominal Attributes:}
    These attributes represent categorical data with distinct, non-ordered values. 
    Examples include days of the week (Monday, Tuesday, etc.) or types of diseases 
    (cancer, diabetes, etc.).
    \item \textit{Ordinal Attributes:}
    These attributes represent categorical data with values that exhibit an inherent 
    order. However, the difference between consecutive values may not be interpretable 
    in terms of a consistent unit.  Examples include customer satisfaction ratings 
    (1-star, 2-star, etc.) or movie ratings (G, PG, PG-13, etc.). In ordinal 
    attributes, the numerical value itself might not be as important as the relative 
    order it represents.
\end{itemize}

Using the \textit{analysys\_attributes.py} script, we can identify the 
Continuous Numeric Attributes and Discrete Nominal Attributes in a specific 
dataset. The script will output statistics that can be showed in Tables 
\ref{tab:continuous_numeric_attributes_salary} and 
\ref{tab:continuous_numeric_attributes_stroke} for numeric attributes and
Table \ref{tab:discrete_nominal_attributes_salary} and 
\ref{tab:discrete_nominal_attributes_stroke} for nominal attributes.

Moreover, the total number of items in the full dataset is 9999 for the Salary
Prediction dataset and 5110 for the Stroke Prediction dataset.


\begin{center}
    \begin{longtable}{ |>{\centering\arraybackslash}m{0.95cm}||>{\centering\arraybackslash}m{1.75cm}|>{\centering\arraybackslash}m{1.75cm}|>{\centering\arraybackslash}m{1.75cm}|>{\centering\arraybackslash}m{1.75cm}|>{\centering\arraybackslash}m{1.75cm}|>{\centering\arraybackslash}m{1.75cm}|>{\centering\arraybackslash}m{1.75cm} |}
        \hline
        \multicolumn{8}{|c|}{List of all Continuous Numeric Attributes in the Salary Prediction dataset} \\
        \hline
         & fnl & hpw & gain & edu\_int & years & loss & prod \\
        \hline\hline
        count & 9.999000e +03 & 9199.00000 & 9999.00000 & 9999.00000 & 9999.00000 & 9999.00000 & 9999.00000 \\
        \hline
        mean &  1.903529e +05 & 40.416241 & 979.853385 & 14.262026 & 38.646865 & 84.111411 & 2014.9275 93 \\
        \hline
        std & 1.060709e +05 & 12.517356 & 7003.7953 82 & 24.770835 & 13.745101 & 3394.0354 84 & 14007.6044 96 \\
        \hline
        min & 1.921400e +04 & 1.000000 & 0.000000 & 1.000000 & 17.000000 & 0.000000 & -28.000000 \\
        \hline
        25\% & 1.182825e +05 & 40.000000 & 0.000000 & 9.000000 & 28.000000 & 0.000000 & 42.000000 \\
        \hline
        50\% & 1.784720e +05 & 40.000000 & 0.000000 & 10.000000 & 37.000000 & 0.000000 & 57.000000 \\
        \hline
        75\% & 2.373110e +05 & 45.000000 & 0.000000 & 13.000000 & 48.000000 & 0.000000 & 77.000000 \\
        \hline
        max & 1.455435e +06 & 99.00000 & 99999.0000 & 206.000000 & 90.000000 & 3770.00000 & 200125.000 \\
        \hline
        \caption{Continuous Numeric Attributes in Salary Prediction Dataset}
        \label{tab:continuous_numeric_attributes_salary} \\
   \end{longtable}
\end{center}

\begin{center}
    \begin{longtable}{ |>{\centering\arraybackslash}m{1cm}||>{\centering\arraybackslash}m{2.25cm}|>{\centering\arraybackslash}m{2.25cm}|>{\centering\arraybackslash}m{2.25cm}|>{\centering\arraybackslash}m{2.25cm}|>{\centering\arraybackslash}m{2.25cm}|}
        \hline
        \multicolumn{6}{|c|}{List of all Continuous Numeric Attributes in the Stroke Prediction dataset} \\
        \hline
        & mean\_blood\_ sugar\_level & cardiovascular\_ issues & body\_mass\_ indicator & high\_ blood\_pressure & years\_old \\
        \hline\hline
        count & 5110.000000 & 5110.000000 & 4909.000000 & 5110.000000 & 5110.000000 \\
        \hline
        mean & 106.147677 & 0.054012 & 28.893237 & 0.097456 & 46.568665 \\
        \hline
        std & 45.283560 & 0.226063 & 7.854067 & 0.296607 & 26.593912 \\
        \hline
        min & 55.120000 & 0.000000 & 10.300000 & 0.000000 & 0.080000 \\
        \hline
        25\% & 77.245000 & 0.000000 & 23.500000 & 0.000000 & 26.000000 \\
        \hline
        50\% & 91.885000 & 0.000000 & 28.100000 & 0.000000 & 47.000000 \\
        \hline
        75\% & 114.090000 & 0.000000 & 33.100000 & 0.000000 & 63.750000 \\
        \hline
        max & 271.740000 & 1.000000 & 97.600000 & 1.000000 & 134.000000 \\
        \hline
    \end{longtable}
    \begin{longtable}{ |>{\centering\arraybackslash}m{1cm}||>{\centering\arraybackslash}m{2.5cm}|>{\centering\arraybackslash}m{2.5cm}|>{\centering\arraybackslash}m{2.5cm}|>{\centering\arraybackslash}m{2.5cm}|}
        \hline
        \multicolumn{5}{|c|}{List of all Continuous Numeric Attributes in the Stroke Prediction dataset} \\
        \hline
        & chaotic\_sleep & analysis\_ results & biological\_ age\_index & cerebrovascular\_ accident \\
        \hline\hline
        count & 5110.000000 & 4599.000000 & 5110.000000 & 5110.000000 \\
        \hline
        mean & 0.054012 & 323.523446 & 134.784256 & 0.048728 \\
        \hline
        std & 0.226063 & 101.577442 & 50.399352 & 0.215320 \\
        \hline
        min & 0.000000 & 104.829714 & -15.109456 & 0.000000 \\
        \hline
        25\% & 0.000000 & 254.646209 & 96.710581 & 0.000000 \\
        \hline
        \hline
        50\% & 0.000000 & 301.031628 & 136.374631 & 0.000000 \\
        \hline
        \hline
        75\% & 0.000000 & 362.822769 & 172.507322 & 0.000000 \\
        \hline
        max & 1.000000 & 756.807975 & 266.986321 & 1.000000 \\
        \hline
        \caption{Continuous Numeric Attributes in Stroke Prediction Dataset}
        \label{tab:continuous_numeric_attributes_stroke} \\
   \end{longtable}
\end{center}

\begin{center}
    \begin{longtable}{ |>{\centering\arraybackslash}m{5cm}|||>{\centering\arraybackslash}m{3cm}|>{\centering\arraybackslash}m{3cm}|}
        \hline
        \multicolumn{3}{|c|}{List of all Discrete Nominal Attributes in the Salary Prediction dataset} \\
        \hline
        & Non-missing count & Unique values count \\
        \hline\hline
        \hline
        country & 9999 & 41 \\
        \hline
        job & 9999 & 14 \\
        \hline
        work\_type & 9999 & 9 \\
        \hline
        partner & 9999 & 7 \\
        \hline
        edu & 9999 & 16 \\
        \hline
        gender & 9199 & 2 \\
        \hline
        race & 9999 & 5 \\
        \hline
        gtype & 9999 & 2 \\
        \hline
        money & 9999 & 2 \\
        \hline
        \caption{Discrete Nominal Attributes in Salary Prediction Dataset}
        \label{tab:discrete_nominal_attributes_salary} \\
    \end{longtable}
\end{center}

\begin{center}
    \begin{longtable}{ |>{\centering\arraybackslash}m{5cm}|||>{\centering\arraybackslash}m{3cm}|>{\centering\arraybackslash}m{3cm}|}
        \hline
        \multicolumn{3}{|c|}{List of all Discrete Nominal Attributes in the Stroke Prediction dataset} \\
        \hline
        & Non-missing count & Unique values count \\
        \hline\hline
        job\_category & 5110 & 5 \\
        \hline
        sex & 5110 & 2 \\
        \hline
        tobacco\_usage & 5110 & 4 \\
        \hline
        married & 4599 &2 \\
        \hline
        living\_area & 5110 & 2 \\
        \hline

        \caption{Discrete Nominal Attributes in Stroke Prediction Dataset}
        \label{tab:discrete_nominal_attributes_stroke} \\
    \end{longtable}
\end{center}

\subsection{Investigation of Class Distribution}
TODO

\subsection{Analysis of Feature Correlations}
TODO

% ------------------------------------------------------------------------------
\section{Data Preprocessing}

% ------------------------------------------------------------------------------
\section{Algorithms Designs}

% ------------------------------------------------------------------------------

\section{Evaluation}

% ------------------------------------------------------------------------------
\section{Conclusions}


\pagebreak
% ------------------------------------------------------------------------------

% ---- Bibliography ----
\begin{thebibliography}{8}
    \bibitem{}
    \href{https://en.wikipedia.org/wiki/A*_search_algorithm#Complexity}{A* search algorithm - Wikipedia}
    \bibitem{}
    \href{https://en.wikipedia.org/wiki/Hill_climbing}{Hill Climbing - Wikipedia}
    \bibitem{}
    \href{https://curs.upb.ro/2023/course/view.php?id=13749}{Moodle - Artifical Intelligence Course}
    \bibitem{}
    \href{https://www.researchgate.net/profile/Kian-Pokorny/publication/262277120_Multiple_constraint_satisfaction_problems_using_the_A-star_A_search_algorithm_classroom_scheduling_with_preferences/links/5e57f530299bf1bdb8408b03/Multiple-constraint-satisfaction-problems-using-the-A-star-A-search-algorithm-classroom-scheduling-with-preferences.pdf}{Multiple constraint satisfaction problems using the A-star search algorithm}
    \bibitem{}
    \href{https://d1wqtxts1xzle7.cloudfront.net/68245993/14443-libre.pdf?1626958962=&response-content-disposition=inline%3B+filename%3DCourses_timetabling_based_on_hill_climbi.pdf&Expires=1714507660&Signature=JDd-gaDdE4E7s5P66Op535FyEuysvPoA5o4fcwak4NWT1sQNtVh50ooYa9eSrHu~aHR-Ulabenz910uDjozKpgHivCFkhipTT5bJJL9MensZTSib8TBVzGtBU9lycqCVwilt21Udi0DMgfhERDSgCcR4vO8hmlFlxOLg1exD1fNLE8kxt4S0H2Qfb3nQEHu3kLsicuJNk8wfF~eWpEDUlWsjW9J9IpxuLWP0OICQ7ZReWtx37dHnPN2PTVmFs815NMNi-jyLV0gWWBTAOL7Hn7A5VSg-l~s2e8RAoCjPAYQDRnnznIzOElRy2nTsgkW3mZDzlsntJ3lFur2KquwqNg__&Key-Pair-Id=APKAJLOHF5GGSLRBV4ZA}{Courses timetabling based on hill climbing algorithm}
    
    \end{thebibliography}
\end{document}